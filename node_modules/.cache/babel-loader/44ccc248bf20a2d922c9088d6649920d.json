{"ast":null,"code":"import _classCallCheck from\"/Users/chendian/Desktop/Projet/Personnelle/Portofolio/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/classCallCheck\";import _createClass from\"/Users/chendian/Desktop/Projet/Personnelle/Portofolio/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createClass\";import _createSuper from\"/Users/chendian/Desktop/Projet/Personnelle/Portofolio/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createSuper\";import _inherits from\"/Users/chendian/Desktop/Projet/Personnelle/Portofolio/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/inherits\";import React,{Component}from'react';import{Container,Row,Col,Button,Badge}from'react-bootstrap';import'./Styles.css';var AppTFReact=/*#__PURE__*/function(_Component){_inherits(AppTFReact,_Component);var _super=_createSuper(AppTFReact);function AppTFReact(){_classCallCheck(this,AppTFReact);return _super.apply(this,arguments);}_createClass(AppTFReact,[{key:\"render\",value:function render(){return/*#__PURE__*/React.createElement(\"div\",{style:{backgroundColor:\"ivory\"}},/*#__PURE__*/React.createElement(Container,{className:\"header\"},/*#__PURE__*/React.createElement(Row,null,/*#__PURE__*/React.createElement(Col,null),/*#__PURE__*/React.createElement(Col,null))),/*#__PURE__*/React.createElement(Container,{className:\"header\"},/*#__PURE__*/React.createElement(Row,null,/*#__PURE__*/React.createElement(Col,null),/*#__PURE__*/React.createElement(Col,{xs:8},/*#__PURE__*/React.createElement(\"h2\",{className:\"heading\"},\" Build an APP in React Native for Image Recognition with TensorFlow\"),/*#__PURE__*/React.createElement(Badge,{pill:true,variant:\"primary\"},\"TensorFlow\"),' ',/*#__PURE__*/React.createElement(Badge,{pill:true,variant:\"success\"},\"React Native\"),' ',/*#__PURE__*/React.createElement(Badge,{pill:true,variant:\"danger\"},\"Image Classification\"),' ',/*#__PURE__*/React.createElement(Badge,{pill:true,variant:\"warning\"},\"JavaScript\"),' ',/*#__PURE__*/React.createElement(\"p\",{className:\"context\"},\"On February 04, 2020, TensorFlow posted a \",/*#__PURE__*/React.createElement(\"a\",{href:\"https://blog.tensorflow.org/2020/02/tensorflowjs-for-react-native-is-here.html\"},\"blog \"),\"formally announcing its support for React Native. This tfjs-react-native package supports GPU backend, Model Loading and Saving, Training, Image & Video Handling. In this blog, we will mainly talk about how to deploy a pre-trained model of image classification in React-Native for offline image recognition.\"),/*#__PURE__*/React.createElement(\"hr\",null),/*#__PURE__*/React.createElement(\"h4\",{className:\"subheading\"},\"Introduction & Motivation \"),/*#__PURE__*/React.createElement(\"p\",null,\"I came across this topic during my internship that the company asked me to make an app in React-Native which identifies products by taking photos. React Native is a framework developed by Facebook for building apps of ios and android. It mainly uses Javascript for coding. For conveience, I trained the model of image classification with TensorFlow for python. Thanks to this fresh \",/*#__PURE__*/React.createElement(\"em\",null,/*#__PURE__*/React.createElement(\"strong\",null,\"tfjs-react-native package \")),\", we can now deploy models trained in python in the envrionment Javascript. This blog will not talk about how to train an image classification model , but will focus on how to deploy the model in React Native.\"),/*#__PURE__*/React.createElement(\"h4\",{className:\"subheading\"},\"Model Preparation \"),/*#__PURE__*/React.createElement(\"p\",null,\"We could find numerous pre-trained models for image classification in \",/*#__PURE__*/React.createElement(\"a\",{href:\"https://tfhub.dev/\"},\"TensorFlow hub\"),\". For exemple, we can select :\",/*#__PURE__*/React.createElement(\"ul\",null,/*#__PURE__*/React.createElement(\"li\",null,\"Problem domain: Image Classfication \"),/*#__PURE__*/React.createElement(\"li\",null,\"Architecture: MobileNet V2\"),/*#__PURE__*/React.createElement(\"li\",null,\"Dataset: ImageNet(ILSVRC-2012-CLS)\")),\"Of course, we could choose another architecture or dataset. It depends on what scenario you want to apply it to. Here we have chosen MobileNet V2 as it is an optimised neural network architecture for efficient on-device image classification and related tasks. The dataset ImageNet is also one of the most used dataset for image classification. In addition to these basic options, we need to pay more attention to the size of the input image that the model requires. Take \",/*#__PURE__*/React.createElement(\"a\",{href:\"https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/classification/4\"},\"this model \"),\"for example, its input size is 224x224 pixels. It means that each input image should be treated to fit the input size of the model before using the model.\"),/*#__PURE__*/React.createElement(\"p\",null,\"Then we can train a customized model from these pre-trained models with the technique \",/*#__PURE__*/React.createElement(\"em\",null,/*#__PURE__*/React.createElement(\"strong\",null,\"Transfer Learning\")),\". This will acquire a propre dataset and some basic knowledge of machine learning. We're not going to get into that this time. Generally, we will train the model with TensorFlow for python and the format of the trained model will be \",/*#__PURE__*/React.createElement(\"em\",null,/*#__PURE__*/React.createElement(\"strong\",null,\"SavedModel\")),\".\"),/*#__PURE__*/React.createElement(\"h4\",{className:\"subheading\"},\"Conversion of the model\"),/*#__PURE__*/React.createElement(\"p\",null,\"Since the environment of React Native is Javascript, we have to convert the SavedModel in .js format with \",/*#__PURE__*/React.createElement(\"a\",{href:\"https://github.com/tensorflow/tfjs/tree/master/tfjs-converter\"},\"TF.js converter\"),\" to get the model in .js. So why we don't use the js format of pre-trained model from the hub ? Let's firstly see the config parameters of the converter and explain why. After installation as guided, we can convert the model with these conversion flags:\",/*#__PURE__*/React.createElement(\"ul\",null,/*#__PURE__*/React.createElement(\"li\",null,\"input_format=\",/*#__PURE__*/React.createElement(\"em\",null,/*#__PURE__*/React.createElement(\"strong\",null,\"tf_saved_model\"))),/*#__PURE__*/React.createElement(\"li\",null,\"output_format=\",/*#__PURE__*/React.createElement(\"em\",null,/*#__PURE__*/React.createElement(\"strong\",null,\"tfjs_graph_model\"))),/*#__PURE__*/React.createElement(\"li\",null,\"weight_shard_size_bytes= 4MB/8MB/...\")),\"The converter will generate a model.json with a bunch of \",/*#__PURE__*/React.createElement(\"em\",null,/*#__PURE__*/React.createElement(\"strong\",null,\"group1-shard1ofN.bin \")),\" files. The model.json represents the architecture of the model and the group-shard.bin files are the weights of the model. Since the tfjs-react-native package only supports one group1-shard.bin file, we have to set the flag weight_shard_size_bytes as large as it could to make sure that only one group-shard.bin file will be generated. Actually, the model of .js format downloaded from the hub contain piles of group-shard.bin files which can not be used in React-Native.\"),/*#__PURE__*/React.createElement(\"h4\",{className:\"subheading\"},\"Deployment in React Native\"),/*#__PURE__*/React.createElement(\"p\",null,\"Firstly, we will put the model files in local file system so that the app can read the files offline. Then we will create a component in React Native called Camera. This component controls the following two functions:\",/*#__PURE__*/React.createElement(\"ul\",null,/*#__PURE__*/React.createElement(\"li\",null,\"takePicture : Take and process the pictures  \"),/*#__PURE__*/React.createElement(\"li\",null,\"callModelPrediction: Apply the model stored in the file system\"))),/*#__PURE__*/React.createElement(\"p\",null,\"In the function takePicture, we will firstly call \",/*#__PURE__*/React.createElement(\"em\",null,/*#__PURE__*/React.createElement(\"strong\",null,\"RNCamera\")),\" to take a picture of the object. We will then process the image to meet the needs of the model input. We will take the following steps:\",/*#__PURE__*/React.createElement(\"ul\",null,/*#__PURE__*/React.createElement(\"li\",null,\"Resize the image\"),/*#__PURE__*/React.createElement(\"li\",null,\"Reformatting the image : datatype, encoding format, Pixel range\")),\"For exemple, the model we use usually requires an image size 1*224*224*3, float32 datatype, tensor encoding format, pixel range[0,1], then we need to take the following steps:\",/*#__PURE__*/React.createElement(\"ul\",null,/*#__PURE__*/React.createElement(\"li\",null,\"Crop the image to 224*224*3 with \",/*#__PURE__*/React.createElement(\"em\",null,/*#__PURE__*/React.createElement(\"strong\",null,\"ImageEditor\"))),/*#__PURE__*/React.createElement(\"li\",null,\"Convert data encoding format from base64 to Uint8Array, and then from Uint8Array to Tensor Object\"),/*#__PURE__*/React.createElement(\"li\",null,\"Normalize the pixel range from [0,255] to [0,1]\"),/*#__PURE__*/React.createElement(\"li\",null,\"Convert datatype to float32\"))),/*#__PURE__*/React.createElement(\"p\",null,\"After following these steps, we will get an image which meet the model input : \",/*#__PURE__*/React.createElement(\"em\",null,/*#__PURE__*/React.createElement(\"strong\",null,\"[1*224*224*3], float32, Tensor Object,  Pixel values [0, 1]\")),\". Now this processed image can be used as the input to call the model for making a prediction. There are no complicated processing steps in this step. Just remember the most important thing : Model calling method should match the model converter process. That means, we should use \",/*#__PURE__*/React.createElement(\"em\",null,/*#__PURE__*/React.createElement(\"strong\",null,\"tf.loadGraphModel\")),\" to call the model since we convert the model tf_saved_model to model tfjs_graph_model. If the output of the model is not a graph model, we can't use the method tf.loadGraphModel.\"),/*#__PURE__*/React.createElement(\"p\",null,\"The model will output the result after 5 or 10 seconds after calling. The output is an array which represents each possibility for each class of objects. We can extract the maximum possibility and its index to do further processing, for exemple, comparing with the database to find the corresponding product name.\"),/*#__PURE__*/React.createElement(\"h4\",{className:\"subheading\"},\"Demo\"),/*#__PURE__*/React.createElement(\"p\",null,\"Here I'm showing an app made during my internship for the company that can identify specific products offline. It includes an image classification model that recognizes 14 products. For some products, the recognition accuracy is almost 100%. Of course, the accuracy of the model depends heavily on the dataset, and the angle of the shot will also have an impact on the results. Anyway, this was a bold and encouraging experiment for me. I hope this article can help you with how to apply machine learning to your React-Native application! You can also find an exemple script in my \",/*#__PURE__*/React.createElement(\"a\",{href:\"https://github.com/diancici/APP-React-Native-Build-with-TensorFlow-.git\"},\"github\"),\".\"),/*#__PURE__*/React.createElement(\"iframe\",{width:\"560\",height:\"315\",src:\"https://www.youtube.com/embed/dNqdTC97NVM\",frameborder:\"0\",allow:\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\",allowfullscreen:true,title:\"Video: Demo mobile APP for Image Recognition by taking photos \"},/*#__PURE__*/React.createElement(\"p\",null,/*#__PURE__*/React.createElement(\"a\",{href:\"https://www.youtube.com/embed/dNqdTC97NVM\"},\"Fallback link for browsers that don't support iframes\"))),/*#__PURE__*/React.createElement(\"hr\",null)),/*#__PURE__*/React.createElement(Col,null)),/*#__PURE__*/React.createElement(Row,null,/*#__PURE__*/React.createElement(Col,{xs:8}),/*#__PURE__*/React.createElement(Col,null,/*#__PURE__*/React.createElement(Button,{variant:\"secondary\",href:\"/#blog\"},\"More blogs\"),\" \",' '))),/*#__PURE__*/React.createElement(Container,{className:\"footer\"},/*#__PURE__*/React.createElement(Row,null,/*#__PURE__*/React.createElement(Col,null),/*#__PURE__*/React.createElement(Col,null))));}}]);return AppTFReact;}(Component);export default AppTFReact;","map":{"version":3,"sources":["/Users/chendian/Desktop/Projet/Personnelle/Portofolio/src/components/Blog/AppTFReact.js"],"names":["React","Component","Container","Row","Col","Button","Badge","AppTFReact","backgroundColor"],"mappings":"gqBAAA,MAAOA,CAAAA,KAAP,EAAgBC,SAAhB,KAAiC,OAAjC,CACA,OAASC,SAAT,CAAoBC,GAApB,CAAyBC,GAAzB,CAA8BC,MAA9B,CAAsCC,KAAtC,KAAkD,iBAAlD,CAEA,MAAO,cAAP,C,GAGMC,CAAAA,U,kQACO,CACL,mBACI,2BAAK,KAAK,CAAE,CAACC,eAAe,CAAC,OAAjB,CAAZ,eACI,oBAAC,SAAD,EAAW,SAAS,CAAC,QAArB,eACQ,oBAAC,GAAD,mBACA,oBAAC,GAAD,MADA,cAEA,oBAAC,GAAD,MAFA,CADR,CADJ,cAQI,oBAAC,SAAD,EAAW,SAAS,CAAC,QAArB,eACI,oBAAC,GAAD,mBACA,oBAAC,GAAD,MADA,cAEA,oBAAC,GAAD,EAAK,EAAE,CAAE,CAAT,eACI,0BAAI,SAAS,CAAC,SAAd,wEADJ,cAEI,oBAAC,KAAD,EAAO,IAAI,KAAX,CAAY,OAAO,CAAC,SAApB,eAFJ,CAIa,GAJb,cAKI,oBAAC,KAAD,EAAO,IAAI,KAAX,CAAY,OAAO,CAAC,SAApB,iBALJ,CAOa,GAPb,cAQI,oBAAC,KAAD,EAAO,IAAI,KAAX,CAAY,OAAO,CAAC,QAApB,yBARJ,CAUa,GAVb,cAWI,oBAAC,KAAD,EAAO,IAAI,KAAX,CAAY,OAAO,CAAC,SAApB,eAXJ,CAaa,GAbb,cAeI,yBAAG,SAAS,CAAC,SAAb,4DAAiE,yBAAG,IAAI,CAAC,gFAAR,UAAjE,uTAfJ,cAqBI,8BArBJ,cAuBI,0BAAI,SAAS,CAAC,YAAd,+BAvBJ,cAwBI,2aAE0E,2CAAI,+DAAJ,CAF1E,qNAxBJ,cA8BI,0BAAI,SAAS,CAAC,YAAd,uBA9BJ,cA+BI,mHAAyE,yBAAG,IAAI,CAAC,oBAAR,mBAAzE,+CACI,2CACI,qEADJ,cAEI,2DAFJ,cAGI,mEAHJ,CADJ,weAQ6J,yBAAG,IAAI,CAAC,yEAAR,gBAR7J,8JA/BJ,cA0CI,mIAC0F,2CAAI,sDAAJ,CAD1F,0PAE+K,2CAAI,+CAAJ,CAF/K,KA1CJ,cA+CI,0BAAI,SAAS,CAAC,YAAd,4BA/CJ,cAgDI,uJAC8G,yBAAG,IAAI,CAAC,+DAAR,oBAD9G,8QAII,2CACI,2DAAiB,2CAAI,mDAAJ,CAAjB,CADJ,cAEI,4DAAkB,2CAAI,qDAAJ,CAAlB,CAFJ,cAGI,qEAHJ,CAJJ,0EAS6D,2CAAI,0DAAJ,CAT7D,4dAhDJ,cA6DI,0BAAI,SAAS,CAAC,YAAd,+BA7DJ,cA8DI,sQAEI,2CACI,8EADJ,cAEI,+FAFJ,CAFJ,CA9DJ,cAqEI,+FACsD,2CAAI,6CAAJ,CADtD,yJAGI,2CACI,iDADJ,cAEI,gGAFJ,CAHJ,gMAQI,2CACI,+EAAqC,2CAAI,gDAAJ,CAArC,CADJ,cAEI,kIAFJ,cAGI,gFAHJ,cAII,4DAJJ,CARJ,CArEJ,cAoFI,4HAC+E,2CAAI,gGAAJ,CAD/E,0SAGkI,2CAAI,sDAAJ,CAHlI,uLApFJ,cA0FI,yVA1FJ,cA8FI,0BAAI,SAAS,CAAC,YAAd,SA9FJ,cA+FI,knBAIG,yBAAG,IAAI,CAAC,yEAAR,WAJH,KA/FJ,cAqGI,8BAAQ,KAAK,CAAC,KAAd,CAAoB,MAAM,CAAC,KAA3B,CACI,GAAG,CAAC,2CADR,CACoD,WAAW,CAAC,GADhE,CAEI,KAAK,CAAC,0FAFV,CAGI,eAAe,KAHnB,CAGoB,KAAK,CAAC,gEAH1B,eAII,0CACI,yBAAG,IAAI,CAAC,2CAAR,0DADJ,CAJJ,CArGJ,cA+GI,8BA/GJ,CAFA,cAmHA,oBAAC,GAAD,MAnHA,CADJ,cAuHI,oBAAC,GAAD,mBACI,oBAAC,GAAD,EAAK,EAAE,CAAE,CAAT,EADJ,cAEI,oBAAC,GAAD,mBAAK,oBAAC,MAAD,EAAQ,OAAO,CAAC,WAAhB,CAA4B,IAAI,CAAC,QAAjC,eAAL,KAAoE,GAApE,CAFJ,CAvHJ,CARJ,cAqII,oBAAC,SAAD,EAAW,SAAS,CAAC,QAArB,eACA,oBAAC,GAAD,mBACI,oBAAC,GAAD,MADJ,cAEI,oBAAC,GAAD,MAFJ,CADA,CArIJ,CADJ,CAgJH,C,wBAlJoBP,S,EAqJzB,cAAeM,CAAAA,UAAf","sourcesContent":["import React, { Component } from 'react';\nimport { Container, Row, Col, Button, Badge} from 'react-bootstrap';\n\nimport './Styles.css'\n\n\nclass AppTFReact extends Component{\n    render() {\n        return (\n            <div style={{backgroundColor:\"ivory\"}}> \n                <Container className=\"header\" >\n                        <Row>\n                        <Col ></Col>                \n                        <Col ></Col>\n                        </Row>\n                </Container> \n\n                <Container className=\"header\" >\n                    <Row>\n                    <Col ></Col>\n                    <Col xs={8}>\n                        <h2 className='heading'> Build an APP in React Native for Image Recognition with TensorFlow</h2>\n                        <Badge pill variant=\"primary\">\n                            TensorFlow \n                        </Badge>{' '}\n                        <Badge pill variant=\"success\">\n                            React Native\n                        </Badge>{' '}\n                        <Badge pill variant=\"danger\">\n                            Image Classification\n                        </Badge>{' '}\n                        <Badge pill variant=\"warning\">\n                            JavaScript\n                        </Badge>{' '}\n\n                        <p className='context'>On February 04, 2020, TensorFlow posted a <a href=\"https://blog.tensorflow.org/2020/02/tensorflowjs-for-react-native-is-here.html\">blog </a> \n                        formally announcing its support for React Native.  \n                        This tfjs-react-native package supports GPU backend, Model Loading and Saving, Training, Image & Video Handling. In this blog, we will mainly talk about \n                        how to deploy a pre-trained model of image classification in React-Native for offline image recognition.    \n                        </p>\n\n                        <hr></hr>\n\n                        <h4 className='subheading'>Introduction & Motivation </h4>\n                        <p>I came across this topic during my internship that the company asked me to make an app in React-Native which identifies products by taking photos.\n                            React Native is a framework developed by Facebook for building apps of ios and android. It mainly uses Javascript for coding. For conveience, I trained the model of \n                            image classification with TensorFlow for python. Thanks to this fresh <em><strong>tfjs-react-native package </strong></em>, we can now deploy models trained in python in the envrionment Javascript.\n                            This blog will not talk about how to train an image classification model , but will focus on how to deploy the model in React Native.\n                        </p>\n\n                        <h4 className='subheading'>Model Preparation </h4>\n                        <p>We could find numerous pre-trained models for image classification in <a href='https://tfhub.dev/'>TensorFlow hub</a>. For exemple, we can select :\n                            <ul>\n                                <li>Problem domain: Image Classfication </li>\n                                <li>Architecture: MobileNet V2</li>\n                                <li>Dataset: ImageNet(ILSVRC-2012-CLS)</li>\n                            </ul>\n                            Of course, we could choose another architecture or dataset. It depends on what scenario you want to apply it to. Here we have chosen MobileNet V2 \n                            as it is an optimised neural network architecture for efficient on-device image classification and related tasks. The dataset ImageNet is also one of the most used dataset\n                            for image classification. In addition to these basic options, we need to pay more attention to the size of the input image that the model requires. Take <a href='https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/classification/4'>this model </a> \n                            for example, its input size is 224x224 pixels. It means that each input image should be treated to fit the input size of the model before using the model.\n                        </p>   \n                        <p> \n                            Then we can train a customized model from these pre-trained models with the technique <em><strong>Transfer Learning</strong></em>. This will acquire a propre dataset and some basic knowledge\n                            of machine learning. We're not going to get into that this time. Generally, we will train the model with TensorFlow for python and the format of the trained model will be <em><strong>SavedModel</strong></em>.    \n                        </p>\n\n                        <h4 className='subheading'>Conversion of the model</h4>\n                        <p>\n                            Since the environment of React Native is Javascript, we have to convert the SavedModel in .js format with <a href='https://github.com/tensorflow/tfjs/tree/master/tfjs-converter'>TF.js converter</a> to get the model in .js. \n                            So why we don't use the js format of pre-trained model from the hub ? Let's firstly see the config parameters of the converter and explain why.\n                            After installation as guided, we can convert the model with these conversion flags:\n                            <ul>\n                                <li>input_format=<em><strong>tf_saved_model</strong></em></li>\n                                <li>output_format=<em><strong>tfjs_graph_model</strong></em></li>\n                                <li>weight_shard_size_bytes= 4MB/8MB/...</li>\n                            </ul> \n                            The converter will generate a model.json with a bunch of <em><strong>group1-shard1ofN.bin </strong></em> files. The model.json represents the architecture of the model and the group-shard.bin files are the weights of the model. Since the tfjs-react-native package only supports one group1-shard.bin file, we have to set the flag weight_shard_size_bytes\n                            as large as it could to make sure that only one group-shard.bin file will be generated. Actually, the model of .js format downloaded from the hub contain piles of group-shard.bin files which can not be used in React-Native.             \n                        </p>\n\n                        <h4 className='subheading'>Deployment in React Native</h4>\n                        <p>Firstly, we will put the model files in local file system so that the app can read the files offline. Then we will create a component in React Native called Camera.\n                            This component controls the following two functions:\n                            <ul>\n                                <li>takePicture : Take and process the pictures  </li>\n                                <li>callModelPrediction: Apply the model stored in the file system</li>\n                            </ul>\n                        </p>\n                        <p>\n                            In the function takePicture, we will firstly call <em><strong>RNCamera</strong></em> to take a picture of the object. We will then process the image to meet the needs of the model input.\n                            We will take the following steps:\n                            <ul>\n                                <li>Resize the image</li>\n                                <li>Reformatting the image : datatype, encoding format, Pixel range</li>\n                            </ul>\n                            For exemple, the model we use usually requires an image size 1*224*224*3, float32 datatype, tensor encoding format, pixel range[0,1], then we need to take the following steps:\n                            <ul>\n                                <li>Crop the image to 224*224*3 with <em><strong>ImageEditor</strong></em></li>\n                                <li>Convert data encoding format from base64 to Uint8Array, and then from Uint8Array to Tensor Object</li>\n                                <li>Normalize the pixel range from [0,255] to [0,1]</li>\n                                <li>Convert datatype to float32</li>\n                            </ul>\n                        </p>\n                        <p>\n                        After following these steps, we will get an image which meet the model input : <em><strong>[1*224*224*3], float32, Tensor Object,  Pixel values [0, 1]</strong></em>. \n                        Now this processed image can be used as the input to call the model for making a prediction. There are no complicated processing steps in this step.\n                        Just remember the most important thing : Model calling method should match the model converter process. That means, we should use <em><strong>tf.loadGraphModel</strong></em> to call the model\n                        since we convert the model tf_saved_model to model tfjs_graph_model. If the output of the model is not a graph model, we can't use the method tf.loadGraphModel.\n                        </p>\n                        <p>The model will output the result after 5 or 10 seconds after calling. The output is an array which represents each possibility for each class of objects.\n                            We can extract the maximum possibility and its index to do further processing, for exemple, comparing with the database to find the corresponding product name.\n                        </p>\n\n                        <h4 className='subheading'>Demo</h4>\n                        <p>\n                        Here I'm showing an app made during my internship for the company that can identify specific products offline. It includes an image classification model that recognizes 14 products. \n                        For some products, the recognition accuracy is almost 100%. Of course, the accuracy of the model depends heavily on the dataset, and the angle of the shot will also have an impact on the results.\n                        Anyway, this was a bold and encouraging experiment for me. I hope this article can help you with how to apply machine learning to your React-Native application! You can also find an exemple script in \n                        my <a href='https://github.com/diancici/APP-React-Native-Build-with-TensorFlow-.git'>github</a>.\n                        </p>\n                        <iframe width=\"560\" height=\"315\" \n                            src=\"https://www.youtube.com/embed/dNqdTC97NVM\" frameborder=\"0\" \n                            allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" \n                            allowfullscreen title='Video: Demo mobile APP for Image Recognition by taking photos '> \n                            <p> \n                                <a href=\"https://www.youtube.com/embed/dNqdTC97NVM\">\n                                Fallback link for browsers that don't support iframes\n                                </a>\n                            </p>\n                        </iframe>\n                        <hr></hr>\n                    </Col>\n                    <Col ></Col>\n                    </Row>\n                \n                    <Row>\n                        <Col xs={8}></Col>                                   \n                        <Col><Button variant=\"secondary\" href=\"/#blog\">More blogs</Button> {' '}</Col>\n                    </Row>\n                </Container>\n\n                <Container className=\"footer\" >\n                <Row>\n                    <Col ></Col>                \n                    <Col ></Col>\n                </Row>\n                </Container>\n\n            </div>\n\n        );\n    }\n}\n\nexport default AppTFReact;"]},"metadata":{},"sourceType":"module"}